\section{Mirror Descent}
\label{section:mirror-descent}

\begin{algorithm}[t]
\caption{\textsc{Mirror Descent with Varying Regularizer}}
\label{algorithm:mirror-descent-varying-regularizer}
\begin{algorithmic}[1]
\REQUIRE Non-empty closed convex set $K \subseteq V$
\STATE Choose a regularizer $R_0:K \to \R$
\STATE $w_1 \leftarrow \argmin_{w \in K} R_0(w)$
\FOR{$t=1,2,3,\dots$}
\STATE Predict $w_t$
\STATE Observe $\ell_t \in V^*$
\STATE Choose a regularizer $R_t:K \to \R$
\STATE $w_{t+1} \leftarrow \argmin_{w \in K} \left( \langle \ell, w \rangle + \Breg_{R_t}(w, w_t) \right)$
\ENDFOR
\end{algorithmic}
\end{algorithm}


\textsc{Mirror Descent} is a generic algorithm similar to \textsc{Follow The
Regularized Leader} but quite different in details. The algorithm is stated as
Algorithm~\ref{algorithm:mirror-descent-varying-regularizer}. The algorithm is
parametrized by a sequence $\{R_t\}_{t=0}^\infty$ of convex functions $R_t:K
\to \R$ called \emph{regularizers}. Each regularizer $R_t$ can depend on past
loss vectors $\ell_1, \ell_2, \dots, \ell_t$ in an arbitrary way. If $R_t$ is
not differentiable\footnote{Note that this can happen even when $R_t$ is a
restriction of a differentiable function defined on a superset of $K$.  If $K$
is bounded and closed, $R_t$ fails to be differentiable at the boundary of $K$.
If $K$ is a subset of an affine subspace of a dimension smaller than the
dimension of $V$, then $R_t$ fails to be differentiable everywhere.}, Bregman
divergence, $\Breg_{R_t}(u,v) = R(u) - R(v) - \langle \grad R(v), u - v
\rangle$ needs to be defined. This is done by choosing a subgradient map $\grad
R_t:K \to V$, i.e. a function such that $\grad R_t(w)$ is a subgradient of
$R_t$ at a point $w$. If $R_t$ is a restriction of a differentiable function
$R'_t$, it is convenient to define $\grad R_t(w) = \grad R'_t(w)$ for all $w
\in K$. The following lemma bounds regret of \textsc{Mirror Descent}.  Proof
can be found in~\cite{Rakhlin-Sridharan-2009,Duchi-Shalev-Shwartz-Singer-Tewari-2010}.
For completeness we give a proof in~\ref{section:mirror-descent-proofs}.

\begin{lemma}[Regret of Mirror Descent]
\label{lemma:mirror-descent-regret}
Algorithm~\ref{algorithm:mirror-descent-varying-regularizer} satisfies, for any
$u \in K$,
$$
\Regret_T(u)
\le
\sum_{t=1}^T \langle \ell_t, w_t - w_{t+1} \rangle - \Breg_{R_t}(w_{t+1}, w_t) + \Breg_{R_t}(u,w_t) - \Breg_{R_t}(u, w_{t+1}) \; .
$$
\end{lemma}

Several existing algorithms are special cases of \textsc{Mirror Descent}. Most
prominent example is projected gradient descent defined by $w_{t+1} = \Pi_K(w_t
- \eta_t \ell_t)$ where $\Pi_K$ is the Euclidean projection to $K$ and
$\eta_t>0$ is the step size.  Projected gradient descent is an instance of
\textsc{Mirror Descent} with regularizer $R_t(w) = \frac{1}{2\eta_t}\|w\|_2^2$.
A special case of projected gradient descent with step size $\eta_t =
\frac{1}{\sqrt{t}}$ is Zinkevich's \textsc{Generalized Infinitesimal Gradient
Ascent} (GIGA) algorithm~\cite{Zinkevich-2003}. Full-matrix and diagonal
versions of \textsc{AdaGrad with Composite Mirror Descent
Update}~\cite{Duchi-Hazan-Singer-2011} are an instances of \textsc{Mirror
Descent} for any bounded $K$ with regularizers
$$
R_t(w) = \frac{1}{2} w^\top \left(\sum_{i=1}^t \ell_i \ell_i^\top \right)^{1/2} \!\!\!\! w
\qquad \text{and} \qquad
R_t(w) = \frac{1}{2} \sum_{j=1}^d w_j^2 \sqrt{ \sum_{i=1}^t \ell_{i,j}^2}
$$
respectively. When $d=1$, both algorithms are equivalent to
\begin{equation}
\label{equation:ada-grad-regularizer}
R_t(w) = \frac{\|w\|_2^2}{2} \sqrt{\sum_{i=1}^t \|\ell_i\|_2^2 } \; .
\end{equation}
All three sequences of regularizers give a scale-free algorithm. Regularizer
\eqref{equation:ada-grad-regularizer} can be viewed as a scale-free generalization of
Zinkevich's GIGA algorithm. In particular, when $\|\ell_i\|_2 = 1$ for all $i$,
\textsc{Mirror Descent} with regularizer \eqref{equation:ada-grad-regularizer}
coincides with GIGA.

\textsc{Exponentially-Weighted Average Forecaster}~\cite[Chapter
2]{Cesa-Bianchi-Lugosi-2006} with constant learning rate $\eta$ for the problem
of prediction with expert advice is an instance of \textsc{Mirror Descent} for
the probability simplex $K = \{ w \in \R^d ~:~ w_j \ge 0, \sum_{j=1}^d w_j = 1
\}$ with negative entropy regularizer $R_t(w) = \frac{1}{\eta} \sum_{j=1}^d w_j
\ln w_j$ where $R_t:K \to \R$. Note that this algorithm is \emph{not}
scale-free.

Replacing $\frac{1}{2}\|w\|_2^2$ in equation \eqref{equation:ada-grad-regularizer} with
an arbitrary convex function $R:K \to \R$ yields
\begin{equation}
\label{equation:scale-free-mirror-descent}
R_t(w) = R(w) \sqrt{\sum_{i=1}^t \|\ell_i\|_*^2} \; .
\end{equation}
We call the resulting algorithm \textsc{Scale-Free Mirror Descent} with
regularizer $R$.  Generalizing existing regret bound for
\textsc{AdaGrad}~\cite{Duchi-Hazan-Singer-2011} we can upper bound its regret.
Proof is a generalization of the proof
of~\cite{Duchi-Shalev-Shwartz-Singer-Tewari-2010,Duchi-Hazan-Singer-2011} and
it can be found can be found in~\ref{section:mirror-descent-proofs}.

\begin{theorem}[Regret of Scale-Free Mirror Descent]
\label{theorem:regret-scale-free-mirror-descent}
Suppose $K \subseteq V$ is a non-empty closed convex subset. Suppose that $R:K
\to \R$ is a $\lambda$-strongly convex function with respect to a norm
$\|\cdot\|$.  \textsc{Scale-Free Mirror Descent} with regularizer $R$ satisfies
for any $u \in K$,
$$
\Regret_T(u) \le \left( \frac{1}{\lambda} + \sup_{v \in K} \Breg_R(u,v) \right) \sqrt{\sum_{t=1}^T \|\ell_t\|_*^2} \; .
$$
\end{theorem}

We choose regularizer $R(w) = \lambda f(w)$ where $f$ is a $1$-strongly convex
function and optimize $\lambda$. The result is the following Corollary. Its proof is trivial.

\begin{corollary}[Regret of Scale-Free Mirror Descent]
\label{corollary:regret-scale-free-mirror-descent}
Suppose $K \subseteq V$ is a non-empty bounded closed convex subset.  Suppose
that $f:K \to \R$ is a $1$-strongly convex function with respect to a norm
$\|\cdot\|$.  \textsc{Scale-Free Mirror Descent} with regularizer
$$
R(w) = \frac{f(w)}{\displaystyle \sqrt{\sup_{u,v \in K} \Breg_f(u,v)}}
\quad \text{satisfies} \quad %
\Regret_T \le 2 \sqrt{\sup_{u,v \in K} \Breg_f(u,v) \sum_{t=1}^T \|\ell_t\|_*^2} \; .
$$
\end{corollary}

The regret bound for \textsc{Scale-Free Mirror Descent}
in the Corollary~\ref{corollary:regret-scale-free-mirror-descent}
depends on $\sup_{u,v \in K} \Breg_f(u,v)$. In contrast,
the regret bounds for \textsc{AdaFTRL} and \textsc{SOLO FTRL}
in Corollaries~\ref{corollary:ada-ftrl-regret-bound}~and~\ref{corollary:regret-solo-ftrl-bounded-set}
depend on $\sup_{u \in K} f(u)$.
Similarly, regret bound in Theorem~\ref{theorem:regret-scale-free-mirror-descent} for
\textsc{Scale-Free Mirror Descent} depends on $\sup_{v \in K} \Breg_R(u,v)$ and
regret bounds in Theorems~\ref{theorem:ada-ftrl-regret-bound}~and~\ref{theorem:regret-solo-ftrl}
for \textsc{AdaFTRL} and \textsc{SOLO FTRL} depend on $R(u)$. It is not hard to show that
\begin{equation}
\label{equation:regularizer-vs-divergence}
\forall u \in K \qquad R(u) \le \sup_{v \in K} \Breg_R(u,v)
\end{equation}
provided that at the minimizer $v^* = \argmin_{v \in K} R(v)$ both $R(v^*)$ and
$\grad R(v^*)$ are zero. Indeed, in that case, $R(u) = \Breg_R(u,v^*) \le
\sup_{v \in K} \Breg_R(u,v)$.

The assumption $R(v^*) = 0$ and $\grad R(v^*) = 0$
are easy to achieve by adding an affine function to the regularizer:
$$
R'(u) = R(u) - \langle \grad R(v^*), u - v^* \rangle - R(v^*) \; .
$$
The regularizer $R'$ has the same parameter of strong convexity as $R$, the
associated Bregman divergences $\Breg_{R'}$ and $\Breg_{R}$ are equal, $R'$ and
$R$ have the same minimizer $v^*$, and $\grad R'(v^*)$ and $\grad R'(v^*)$ are
both zero.

Thus, \eqref{equation:regularizer-vs-divergence} implies that ignoring constant
factors, regret bound for \textsc{Scale-Free Mirror Descent} is \emph{not}
better and possibly worse than the regret bounds for \textsc{AdaFTRL} and
\textsc{SOLO FTRL}.  In fact, it is not hard to come up with examples where
$R(u)$ is finite whereas $\sup_{v \in K} \Breg_R(u,v)$ is infinite. We mention
two such examples. The first example is $R(w) = \frac{1}{2}\|w\|_2^2$ defined
on the whole space $V$, where for any $u \in V$, $R(u)$ is a finite value but
$\sup_{v \in K} \Breg_R(u,v) = \sup_{v \in V} \frac{1}{2}\|u-v\|_2^2 =
+\infty$. The second example is the negative entropy regularizer $R(w) = \ln d
+ \sum_{j=1}^d w_j \ln w_j$ defined on the $d$-dimensional probability simplex
$K = \{ w \in \R^d ~:~ w_j \ge 0, \sum_{j=1}^d w_j = 1 \}$, where for any $u
\in K$, $R(u)$ is finite and in fact lies in the interval $[-\ln d, 0]$ but
$\sup_{v \in K} \Breg_R(u,v) = \sup_{v \in K} \sum_{j=1}^d u_j \ln(u_j/v_j) = +
\infty$. We return to these examples in the following subsection.

\subsection{Lower Bounds}

The bounds in Theorem~\ref{theorem:regret-scale-free-mirror-descent} and
Corollary~\ref{corollary:regret-scale-free-mirror-descent} are vacuous when
$\Breg_R(u,v)$ is not bounded. One might wonder if the assumption that
$\Breg_R(u,v)$ is bounded is necessary in order for \textsc{Scale-Free Mirror Descent}
to have a ``small'' regret. We show necessity of this assumption on
two counter-examples.  In these
counter-examples, we consider strongly convex regularizers $R$ such that
$\Breg_R(u,v)$ is not bounded and we construct sequences of loss vectors
$\ell_1, \ell_2, \dots, \ell_T$ such that $\|\ell_1\|_* = \|\ell_2\|_* = \dots
= \|\ell_T\|_* = 1$ and \textsc{Scale-Free Mirror Descent} has regret
$\Omega(T)$ or worse.

The first counter-example is stated as
Theorem~\ref{theorem:first-counter-example} below. The decision set is the
whole space $K=V$ and the regularizer is $R(w) = \frac{1}{2}\|w\|_2^2$. Note
that $R(w)$ is $1$-strongly convex with respect to $\|\cdot\|_2$ and the dual
norm of $\|\cdot\|_2$ is $\|\cdot\|_2$. Corresponding Bregman divergence is
$\Breg_R(u,v) = \frac{1}{2}\|u-v\|_2^2$. The counter-example constructs
sequence of unit-norm loss vectors in the one-dimensional subspace spanned by
the first vector of the standard unit basis.  On such sequence, Zinkevich's
\textsc{GIGA} and both versions of \textsc{AdaGrad with Composite Mirror
Update} have predictions identical to \textsc{Scale-Free Mirror Descent}. Hence
the lower bound applies to all four algorithms.

\begin{theorem}[First Counter-Example]
\label{theorem:first-counter-example}
Suppose $K = V$. For any $T \ge 42$ there exists a sequence of loss vectors
$\ell_1, \ell_2, \dots, \ell_T \in V^*$ such that $\|\ell_1\|_2 = \|\ell_2\|_2
= \dots = \|\ell_T\|_2 = 1$ and \textsc{Scale-Free Mirror Descent} with
regularizer $R(w) = \frac{1}{2}\|w\|_2^2$, Zinkevich's \textsc{GIGA} algorithm,
and both versions of \textsc{AdaGrad with Composite Mirror Descent Update}
satisfy
$$
\Regret_T(0) \ge \frac{T^{3/2}}{20} \; .
$$
\end{theorem}

The second counter-example is stated as Theorem~\ref{theorem:second-counter-example}
below.  The decision set is the $d$-dimensional probability simplex $K = \{ w
\in \R^d ~:~ w_j \ge 0, \sum_{j=1}^d w_j = 1 \}$ and the regularizer is the
negative entropy $R(w) = \sum_{j=1}^d w_j \ln w_j$.  Negative entropy is
$1$-strongly convex with respect to $\|\cdot\|_1$ and the dual norm of
$\|\cdot\|_1$ is \mbox{$\|\cdot\|_\infty$}.  The corresponding Bregman
divergence is the Kullback-Leibler divergence $\Breg_R(u,v) = \sum_{j=1}^d u_j
\ln(u_j/v_j)$.  Note that despite that negative entropy is upper- and
lower-bounded, Kullback-Leibler divergence is unbounded from above.

\begin{theorem}[Second Counter-Example]
\label{theorem:second-counter-example}
Let $d \ge 2$, let $V = \R^d$, and let $K = \{ w \in V ~:~ w_j \ge 0, \sum_{j=1}^d w_j = 1 \}$
be the $d$-dimensional probability simplex.  For any $T \ge 120$
there exists a sequence of loss vectors $\ell_1, \ell_2, \dots, \ell_T \in V^*$
such that $\|\ell_1\|_\infty = \|\ell_2\|_\infty = \dots = \|\ell_T\|_\infty =
1$ and \textsc{Scale-Free Mirror Descent} with regularizer $R(w) = \sum_{j=1}^d
w_j \ln w_j$ satisfies
$$
\Regret_T \ge \frac{T}{6} \; .
$$
\end{theorem}
