\section{Conclusions}
\label{section:conclusions}

We have investigated scale-free algorithms for online linear optimization and
we have shown that scale-free property leads to algorithms which have optimal
regret and do not need to know or assume \textbf{anything} about the sequence
of loss vectors, i.e. without any assumption on the norms of the loss vectors
and the number of rounds. We have designed two scale-free algorithms for online
linear optimization with regret bound $O \left(\sqrt{\sup_{v \in K} f(v)
\sum_{t=1}^T \|\ell\|_*^2} \right)$ where $f$ is any non-negative $1$-strongly
convex function with respect to a norm $\|\cdot\|$ defined on the decision set
and where $\|\cdot\|_*$ is the dual norm to $\|\cdot\|$.  These algorithms are
based on \textsc{Follow The Regularizer Leader}.  We have shown that one of the
algorithms has regret $O \left(f(u) \sqrt{\sum_{t=1}^T \|\ell_t\|_*^2} +
\max_{t=1,2,\dots,T} \|\ell_t\|_* \sqrt{T} \right)$ with respect to any
competitor $u \in K$, where $f$ is any non-negative $1$-strongly convex
function defined on the decision set.  The latter result makes sense even when
the decision set $K$ is unbounded.

Similar, but weaker result holds for a scale-free algorithm based on
\textsc{Mirror Descent}. However, we have also shown this algorithm is strictly
weaker than algorithms based on \textsc{Follow The Regularizer Leader}. Namely,
we gave examples of regularizers for which the associated Bregman divergence is
unbounded and the scale-free version of \textsc{Mirror Descent} has $\Omega(T)$
regret or worse.

We have shown an $\frac{D}{\sqrt{8}} \sqrt{\sum_{t=1}^T \|\ell\|_*^2}$
lower bound on regret of any algorithm for decision set with diameter $D$.
