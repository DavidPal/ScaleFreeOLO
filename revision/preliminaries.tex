\section{Notation and Preliminaries}
\label{section:preliminaries}

Let $V$ be a finite-dimensional\footnote{Many, but not all, of our
results can be extended to more general normed vector spaces.} real vector
space equipped with a norm $\|\cdot\|$. We denote by $V^*$ its dual vector
space.  The bi-linear map associated with $(V^*, V)$ is denoted by $\langle
\cdot, \cdot \rangle:V^* \times V \to \R$.  The dual norm of $\|\cdot\|$ is
$\|\cdot\|_*$.

In OLO, in each round $t=1,2,\dots$, the algorithm chooses a point $w_t$ in the
decision set $K \subseteq V$ and then the algorithm observes a loss vector
$\ell_t \in V^*$. The instantaneous loss of the algorithm in round $t$ is
$\langle \ell_t, w_t \rangle$. The cumulative loss of the algorithm after $T$
rounds is $\sum_{t=1}^T \langle \ell_t, w_t \rangle$.  The regret of the
algorithm with respect to a point $u \in K$ is
$$
\Regret_T(u) = \sum_{t=1}^T \langle \ell_t, w_t \rangle - \sum_{t=1}^T \langle \ell_t, u \rangle,
$$
and the regret with respect to the best point is $\Regret_T= \sup_{u \in K}
\Regret_T(u)$.  We assume that $K$ is a non-empty closed convex subset of $V$.
Sometimes we will assume that $K$ is also bounded. We denote by $D$ its
diameter with respect to $\|\cdot\|$, i.e., $D = \sup_{u,v \in K} \|u - v\|$.
If $K$ is unbounded, $D = +\infty$.

\subsection{Convex Analysis}

The \emph{Bregman divergence} of a convex differentiable function $f$ is
defined as $\Breg_f(u,v) = f(u) - f(v) - \langle \grad f(v), u - v \rangle$.
Note that $\Breg_f(u,v) \ge 0$ for any $u,v$ which follows directly from the
definition of convexity of $f$.

The \emph{Fenchel conjugate} of a function $f:K \to \R$ is the function
$f^*:V^* \to \R \cup \{+\infty\}$ defined as $f^*(\ell) = \sup_{w \in K} \left(
\langle \ell, w \rangle - f(w) \right)$.  The Fenchel conjugate of any function
is convex (since it is a supremum of affine functions) and satisfies
 the \emph{Fenchel-Young inequality}
$$
\forall w \in K, \ \forall \ell \in V^* \qquad \qquad
f(w) + f^*(\ell) \ge \langle \ell, w \rangle \; .
$$

Monotonicity of Fenchel conjugates follows easily from the definition: If
$f,g:K \to \R$ satisfy $f(w) \le g(w)$ for all $w \in K$ then $f^*(\ell) \ge
g^*(\ell)$ for every $\ell \in V^*$.

Given $\lambda > 0$, a function $f:K \to \R$ is called \emph{$\lambda$-strongly
convex} with respect to a norm $\|\cdot\|$ if and only if, for all $x,y \in K$,
$$
f(y) \ge f(x) + \langle \grad f(x), y - x \rangle + \frac{\lambda}{2}\|x - y\|^2 \; ,
$$
where $\grad f(x)$ is any subgradient of $f$ at the point $x$.

The following proposition relates the range of values of a strongly convex
function to the diameter of its domain. The proof can be found
in~\ref{section:definitions-proofs}.

\begin{proposition}[Diameter vs. Range]
\label{proposition:diameter-vs-range}
Let $K \subseteq V$ be a non-empty bounded closed convex set.  Let $D =
\sup_{u,v \in K} \|u - v\|$ be its diameter with respect to $\|\cdot\|$.  Let
$f:K \to \R$ be a non-negative lower semi-continuous function that is
$1$-strongly convex with respect to $\|\cdot\|$.  Then, $D \le \sqrt{8 \sup_{v
\in K} f(v)}$.
\end{proposition}

Fenchel conjugates and strongly convex functions have certain nice properties,
which we list in Proposition~\ref{proposition:conjugate-properties} below.

\begin{proposition}[Fenchel Conjugates of Strongly Convex Functions]
\label{proposition:conjugate-properties}
Let $K \subseteq V$ be a non-empty closed convex set with diameter
$D:=\sup_{u,v \in K} \|u-v\|$.  Let $\lambda > 0$, and let $f:K \to \R$ be a
lower semi-continuous function that is $\lambda$-strongly convex with respect
to $\|\cdot\|$.  The Fenchel conjugate of $f$ satisfies:
\begin{enumerate}

\item $f^*$ is finite everywhere and differentiable everywhere.

\item For any $\ell \in V^*$, $\grad f^*(\ell) = \argmin_{w \in K} \left( f(w) - \langle \ell, w \rangle \right)$

\item For any $\ell \in V^*$, $f^*(\ell) + f(\grad f^*(\ell)) = \langle \ell, \grad f^*(\ell) \rangle$.

\item $f^*$ is $\frac{1}{\lambda}$-strongly smooth, i.e., for any $x,y \in
V^*$, $\Breg_{f^*}(x, y) \le \frac{1}{2\lambda} \|x - y\|_*^2$.

\item $f^*$ has $\frac{1}{\lambda}$-Lipschitz continuous gradients, i.e.,
for any $x,y \in V^*$,
$\|\grad f^*(x) - \grad f^*(y)\| \le \frac{1}{\lambda} \|x - y\|_*$.

\item $\Breg_{f^*}(x,y) \le D\|x-y\|_*$ for any $x,y \in V^*$.

\item $\|\grad f^*(x) - \grad f^*(y)\| \le D$ for any $x,y \in V^*$.

\item For any $c > 0$, $(cf(\cdot))^* = cf^*(\cdot/c)$.
\end{enumerate}
\end{proposition}

Except for properties 6 and 7, the proofs can be found
in~\cite{Shalev-Shwartz-2007}.  Property 6 is proven
in~\ref{section:definitions-proofs}. Property 7 trivially follows from property
2.

\begin{algorithm}[t]
\caption{\textsc{FTRL with Varying Regularizer}}
\label{algorithm:ftrl-varying-regularizer}
\begin{algorithmic}[1]
\REQUIRE Non-empty closed convex set $K \subseteq V$
\STATE Initialize $L_0 \leftarrow 0$
\FOR{$t=1,2,3,\dots$}
\STATE Choose a regularizer $R_t:K \to \R$
\STATE $w_t \leftarrow \argmin_{w \in K} \left( \langle L_{t-1}, w \rangle + R_t(w) \right)$
\STATE Predict $w_t$
\STATE Observe $\ell_t \in V^*$
\STATE $L_t \leftarrow L_{t-1} + \ell_t$
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Generic FTRL with Varying Regularizer}
\label{section:generic-ftrl}

Two of our scale-free algorithms are instances of \textsc{FTRL} with
\emph{varying regularizers}, presented as
Algorithm~\ref{algorithm:ftrl-varying-regularizer}.  The algorithm is
paramatrized by a sequence $\{R_t\}_{t=1}^\infty$ of functions $R_t:K \to \R$
called \emph{regularizers}.  Each regularizer $R_t$ can depend on the past loss
vectors $\ell_1, \ell_2, \dots, \ell_{t-1}$ in an arbitrary way.  The following
lemma bounds its regret.

\begin{lemma}[Regret of \textsc{FTRL}]
\label{lemma:generic-regret-bound}
If the regularizers $R_1, R_2, \dots$ chosen by
Algorithm~\ref{algorithm:ftrl-varying-regularizer} are strongly convex and lower
semi-continuous, the algorithm's regret is upper bounded as
$$
\Regret_T(u) \le R_{T+1}(u) + R_1^*(0) + \sum_{t=1}^{T} \Breg_{R_t^*}(-L_t, -L_{t-1}) - R_t^*(-L_t) + R_{t+1}^*(-L_t) \; .
$$
\end{lemma}

The proof of the lemma can be found in~\cite{Orabona-Crammer-Cesa-Bianchi-2014}.
For completeness, we include it in~\ref{section:definitions-proofs}.


\subsection{Generic Mirror Descent with Varying Regularizer}

\begin{algorithm}[t]
\caption{\textsc{Mirror Descent with Varying Regularizer}}
\label{algorithm:mirror-descent-varying-regularizer}
\begin{algorithmic}[1]
\REQUIRE Non-empty closed convex set $K \subseteq V$
\STATE Choose a regularizer $R_0:K \to \R$
\STATE $w_1 \leftarrow \argmin_{w \in K} R_0(w)$
\FOR{$t=1,2,3,\dots$}
\STATE Predict $w_t$
\STATE Observe $\ell_t \in V^*$
\STATE Choose a regularizer $R_t:K \to \R$
\STATE $w_{t+1} \leftarrow \argmin_{w \in K} \left( \langle \ell_t, w \rangle + \Breg_{R_t}(w, w_t) \right)$
\ENDFOR
\end{algorithmic}
\end{algorithm}

\textsc{Mirror Descent} (MD) is a generic algorithm similar to \textsc{FTRL}
but quite different in the details. The algorithm is stated as
Algorithm~\ref{algorithm:mirror-descent-varying-regularizer}. The algorithm is
parametrized by a sequence $\{R_t\}_{t=0}^\infty$ of convex functions $R_t:K
\to \R$ called \emph{regularizers}. Each regularizer $R_t$ can depend on past
loss vectors $\ell_1, \ell_2, \dots, \ell_t$ in an arbitrary way. If $R_t$ is
not differentiable,\footnote{Note that this can happen even when $R_t$ is a
restriction of a differentiable function defined on a superset of $K$.  If $K$
is bounded and closed, $R_t$ fails to be differentiable at the boundary of $K$.
If $K$ is a subset of an affine subspace of a dimension smaller than the
dimension of $V$, then $R_t$ fails to be differentiable everywhere.} the
Bregman divergence, $\Breg_{R_t}(u,v) = R_t(u) - R_t(v) - \langle \grad R_t(v),
u - v \rangle$ needs to be defined. This is done by choosing a subgradient map
$\grad R_t:K \to V$, i.e., a function such that $\grad R_t(w)$ is a subgradient
of $R_t$ at any point $w$. If $R_t$ is a restriction of a differentiable function
$R'_t$, it is convenient to define $\grad R_t(w) = \grad R'_t(w)$ for all $w
\in K$. The following lemma bounds the regret of \textsc{MD}.

\begin{lemma}[Regret of \textsc{MD}]
\label{lemma:mirror-descent-regret}
Algorithm~\ref{algorithm:mirror-descent-varying-regularizer} satisfies, for any
$u \in K$,
$$
\Regret_T(u)
\le
\sum_{t=1}^T \langle \ell_t, w_t - w_{t+1} \rangle - \Breg_{R_t}(w_{t+1}, w_t) + \Breg_{R_t}(u,w_t) - \Breg_{R_t}(u, w_{t+1}) \; .
$$
\end{lemma}

The proof of the lemma can be found
in~\cite{Rakhlin-Sridharan-2009,Duchi-Shalev-Shwartz-Singer-Tewari-2010}.  For
completeness, we give a proof in~\ref{section:mirror-descent-proofs}.

%Several existing algorithms are special cases of \textsc{MD}.  For example,
%\textsc{Hedge} is an instance of \textsc{MD} for the probability simplex $K =
%\{ w \in \R^d ~:~ w_j \ge 0, \sum_{j=1}^d w_j = 1 \}$ with negative entropy
%regularizer $R_t(w) = \frac{1}{\eta} \sum_{j=1}^d w_j \ln w_j$ where $\eta > 0$
%is a (constant) learning rate. Note that this algorithm is \emph{not}
%scale-free.

%The most prominent instance of \textsc{MD} is \textsc{Projected Gradient
%Descent} defined by the recurrence
%$$
%w_{t+1} = \Pi_K \left( w_t - \eta_t \ell_t \right) \; ,
%$$
%where $\Pi_K(x) = \argmin_{y \in K} \|x-y\|_2$ is the Euclidean projection to
%$K$ and $\eta_t > 0$ is the step size.  \textsc{Projected Gradient Descent} is
%an instance of \textsc{MD} with regularizer $R_t(w) =
%\frac{1}{2\eta_t}\|w\|_2^2$.  A special case of \textsc{Projected Gradient
%Descent} with step size $\eta_t = \frac{1}{\sqrt{t}}$ is \textsc{Generalized
%Infinitesimal Gradient Ascent} (GIGA)~\cite{Zinkevich-2003}.
